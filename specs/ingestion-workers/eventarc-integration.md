# Eventarc Integration: GCS-Driven Event Architecture

## Background

### The Problem with Manual Event Publishing

Our current architecture requires workers to explicitly publish domain events to PubSub after updating storage. This creates potential inconsistencies:

```typescript
// Current approach - two separate operations that can fail independently
yield* store.updateJobStatus(job.id, "Completed", undefined, transcriptId)
yield* pubsub.publishEvent(TranscriptComplete.create({ ... })) // Can fail!
```

### The Eventarc Solution

Eventarc automatically generates events when GCS objects are created/updated. Since our `@puredialog/storage` package already uses GCS for all state changes, we can eliminate manual event publishing entirely:

```typescript
// New approach - single operation, automatic events
yield* store.updateJobStatus(job.id, "Completed", undefined, transcriptId)
// TranscriptComplete event automatically generated by Eventarc!
```

## Index Structure Integration

Our existing `Index` structure perfectly maps to Eventarc path patterns:

### Storage Index (packages/storage/src/indices.ts)
```typescript
export const Index = {
  job: (status: JobStatus, jobId: JobId): string => 
    `jobs/${status}/${jobId}.json`,
  transcript: (transcriptId: TranscriptId): string => 
    `transcripts/${transcriptId}.json`,
  idempotency: (hashedKey: string): string => 
    `idempotency/${hashedKey}.json`
}
```

### Eventarc Path Patterns (infra/index.ts)
```typescript
const triggers = {
  // Matches Index.job() output
  jobEvents: "jobs/{status}/{jobId}.json",
  
  // Matches Index.transcript() output  
  transcriptEvents: "transcripts/{transcriptId}.json"
}
```

## Infrastructure Implementation

### Pulumi Infrastructure Code

```typescript
// infra/index.ts
import * as gcp from "@pulumi/gcp"
import * as pulumi from "@pulumi/pulumi"

const project = pulumi.output(gcp.organizations.getProject({}))
const location = "us-central1"

// Storage bucket for all job data
const jobsBucket = new gcp.storage.Bucket("puredialog-storage", {
  location,
  name: `${project.name}-puredialog-storage`,
  uniformBucketLevelAccess: true,
})

// Events topic for domain events
const eventsTopic = new gcp.pubsub.Topic("puredialog-events", {
  name: "puredialog-events",
})

// Job lifecycle events trigger
const jobEventsTrigger = new gcp.eventarc.Trigger("job-events-trigger", {
  location,
  project: project.projectId,
  destination: {
    cloudRunService: {
      service: "puredialog-api",
      path: "/internal/events/gcs",
      region: location,
    },
  },
  matchingCriterias: [
    { attribute: "type", value: "google.cloud.storage.object.v1.finalized" },
    { attribute: "bucket", value: jobsBucket.name },
  ],
  eventFilters: [{
    attribute: "objectName",
    value: "jobs/{status}/{jobId}.json",
    operator: "match-path-pattern",
  }],
})

// Transcript completion events trigger
const transcriptEventsTrigger = new gcp.eventarc.Trigger("transcript-events-trigger", {
  location,
  project: project.projectId,
  destination: {
    cloudRunService: {
      service: "puredialog-api",
      path: "/internal/events/gcs",
      region: location,
    },
  },
  matchingCriterias: [
    { attribute: "type", value: "google.cloud.storage.object.v1.finalized" },
    { attribute: "bucket", value: jobsBucket.name },
  ],
  eventFilters: [{
    attribute: "objectName",
    value: "transcripts/{transcriptId}.json", 
    operator: "match-path-pattern",
  }],
})
```

## Configuration Management

### Shared Path Constants

Create a shared configuration to ensure consistency between app and infrastructure:

```typescript
// packages/storage/src/paths.ts
export const STORAGE_PATHS = {
  JOBS_PREFIX: "jobs",
  TRANSCRIPTS_PREFIX: "transcripts",
  IDEMPOTENCY_PREFIX: "idempotency",
} as const

export const EVENTARC_PATTERNS = {
  JOB_EVENTS: `${STORAGE_PATHS.JOBS_PREFIX}/{status}/{jobId}.json`,
  TRANSCRIPT_EVENTS: `${STORAGE_PATHS.TRANSCRIPTS_PREFIX}/{transcriptId}.json`,
} as const
```

### Updated Index Using Constants

```typescript
// packages/storage/src/indices.ts
import { STORAGE_PATHS } from "./paths.js"

export const Index = {
  job: (status: JobStatus, jobId: JobId): string =>
    `${STORAGE_PATHS.JOBS_PREFIX}/${status}/${jobId}.json`,
  transcript: (transcriptId: TranscriptId): string =>
    `${STORAGE_PATHS.TRANSCRIPTS_PREFIX}/${transcriptId}.json`,
  idempotency: (hashedKey: string): string =>
    `${STORAGE_PATHS.IDEMPOTENCY_PREFIX}/${hashedKey}.json`
}
```

### Infrastructure Using Constants

```typescript
// infra/index.ts
import { EVENTARC_PATTERNS } from "@puredialog/storage"

const jobEventsTrigger = new gcp.eventarc.Trigger("job-events-trigger", {
  eventFilters: [{
    attribute: "objectName",
    value: EVENTARC_PATTERNS.JOB_EVENTS,
    operator: "match-path-pattern",
  }],
  // ... rest of configuration
})
```

## Event Handler Implementation

### GCS Event Processing

```typescript
// packages/api/src/handlers/internal.ts

interface GcsEvent {
  readonly bucket: string
  readonly name: string        // Object path from our Index
  readonly generation: string
  readonly eventTime: string
  readonly eventType: string
}

const handleGcsEvent = (gcsEvent: GcsEvent) =>
  Effect.gen(function*() {
    const filePath = gcsEvent.name
    const eventTime = new Date(gcsEvent.eventTime)
    
    // Parse path to determine event type
    const jobMatch = filePath.match(/^jobs\/([^\/]+)\/([^\/]+)\.json$/)
    const transcriptMatch = filePath.match(/^transcripts\/([^\/]+)\.json$/)
    
    if (jobMatch) {
      const [, status, jobId] = jobMatch
      yield* handleJobEvent(jobId as JobId, status as JobStatus, eventTime)
      
    } else if (transcriptMatch) {
      const [, transcriptId] = transcriptMatch
      yield* handleTranscriptEvent(transcriptId as TranscriptId, eventTime)
      
    } else {
      yield* Effect.logDebug(`Ignoring GCS event for path: ${filePath}`)
    }
  })

const handleJobEvent = (jobId: JobId, status: JobStatus, eventTime: Date) =>
  Effect.gen(function*() {
    const pubsub = yield* PubSubClient
    const store = yield* JobStore
    
    // Get job context
    const job = yield* store.findJobById(jobId).pipe(
      Effect.flatMap(Option.match({
        onSome: Effect.succeed,
        onNone: () => Effect.fail(new JobNotFound({ jobId, message: "Job not found" }))
      }))
    )
    
    // Create domain event based on status
    const domainEvent = Match.value(status).pipe(
      Match.when("Queued", () => JobQueued.create({
        jobId,
        requestId: job.requestId,
        occurredAt: eventTime
      })),
      Match.when("Processing", () => JobStatusChanged.create({
        jobId,
        requestId: job.requestId,
        from: "Queued",
        to: "Processing", 
        occurredAt: eventTime
      })),
      Match.when("Completed", () => JobStatusChanged.create({
        jobId,
        requestId: job.requestId,
        from: "Processing",
        to: "Completed",
        occurredAt: eventTime
      })),
      Match.when("Failed", () => JobFailed.create({
        jobId,
        requestId: job.requestId,
        error: "Job processing failed",
        occurredAt: eventTime
      })),
      Match.exhaustive
    )
    
    // Publish to events topic
    yield* pubsub.publishEvent(domainEvent)
    
    yield* Effect.logInfo(`Generated domain event: ${domainEvent._tag}`, {
      jobId,
      status
    })
  })

const handleTranscriptEvent = (transcriptId: TranscriptId, eventTime: Date) =>
  Effect.gen(function*() {
    const pubsub = yield* PubSubClient
    const storage = yield* CloudStorageService
    
    // Get transcript data to find associated job
    const transcriptKey = Index.transcript(transcriptId)
    const transcript = yield* storage.download(transcriptKey).pipe(
      Effect.flatMap(data => Effect.tryPromise(() => JSON.parse(data)))
    )
    
    const domainEvent = TranscriptComplete.create({
      jobId: transcript.jobId,
      requestId: transcript.requestId,
      transcript: {
        id: transcriptId,
        location: transcriptKey
      },
      occurredAt: eventTime
    })
    
    yield* pubsub.publishEvent(domainEvent)
    
    yield* Effect.logInfo("Generated TranscriptComplete event", {
      transcriptId,
      jobId: transcript.jobId
    })
  })

// HTTP endpoint for Eventarc webhooks
export const gcsEventHandler = HttpApiBuilder.group(PureDialogApi, "internal", handlers =>
  handlers.handle("gcsEvent", ({ payload }) =>
    Effect.gen(function*() {
      yield* handleGcsEvent(payload)
      return { received: true, processed: true }
    }).pipe(
      Effect.catchAll(error =>
        Effect.gen(function*() {
          yield* Effect.logError("Failed to process GCS event", error)
          return { received: true, processed: false }
        })
      )
    )
  )
)
```

## Worker Service Simplification

With Eventarc handling event publishing, workers become much simpler:

### Before: Manual Event Publishing
```typescript
// worker-transcription (complex)
const processJob = (job: TranscriptionJob) =>
  Effect.gen(function*() {
    const store = yield* JobStore
    const pubsub = yield* PubSubClient
    const llm = yield* LLMService
    
    // Update to Processing
    yield* store.updateJobStatus(job.id, "Processing")
    yield* pubsub.publishEvent(JobStatusChanged.create({ ... }))
    
    // Perform transcription
    const transcript = yield* llm.transcribeMedia(job.media, job.metadata)
    
    // Save transcript
    const transcriptId = TranscriptId.create()
    yield* storage.upload(Index.transcript(transcriptId), transcript)
    
    // Update to Completed  
    yield* store.updateJobStatus(job.id, "Completed", undefined, transcriptId)
    yield* pubsub.publishEvent(TranscriptComplete.create({ ... }))
  })
```

### After: Automatic Event Generation
```typescript
// worker-transcription (simple)
const processJob = (job: TranscriptionJob) =>
  Effect.gen(function*() {
    const store = yield* JobStore
    const llm = yield* LLMService
    const storage = yield* CloudStorageService
    
    // Update to Processing (JobStatusChanged event auto-generated)
    yield* store.updateJobStatus(job.id, "Processing")
    
    // Perform transcription
    const transcript = yield* llm.transcribeMedia(job.media, job.metadata)
    
    // Save transcript (TranscriptComplete event auto-generated)
    const transcriptId = TranscriptId.create()
    yield* storage.upload(Index.transcript(transcriptId), transcript)
    
    // Update to Completed (JobStatusChanged event auto-generated)
    yield* store.updateJobStatus(job.id, "Completed", undefined, transcriptId)
  })
```

## Environment Configuration

### Environment Variables
```bash
# Storage configuration
STORAGE_BUCKET_NAME=puredialog-storage-dev

# Eventarc webhook endpoint
EVENTARC_WEBHOOK_PATH=/internal/events/gcs

# No PubSub configuration needed for workers!
```

### Configuration Service
```typescript
// packages/storage/src/config.ts
export interface StorageConfigInterface {
  readonly bucketName: string
  readonly region: string
}

const StorageConfigSchema = {
  bucketName: Config.string("STORAGE_BUCKET_NAME"),
  region: Config.string("STORAGE_REGION").pipe(
    Config.withDefault("us-central1")
  ),
}

export const StorageConfigLive = Layer.effect(StorageConfig, makeStorageConfig)
```

## Benefits of This Architecture

### 1. Simplified Workers
- No PubSub dependencies in worker services
- Fewer failure points (no manual event publishing)
- Workers focus purely on business logic

### 2. Guaranteed Event Consistency  
- Events automatically generated when storage changes
- No possibility of "storage updated but event missed"
- GCS provides the single source of truth

### 3. Infrastructure as Code Alignment
- Path patterns in Pulumi directly mirror Index structure
- Single place to change path conventions
- Type-safe path generation

### 4. Operational Simplicity
- Fewer moving parts (no PubSub publishing logic)
- Automatic retry handling via Eventarc
- Built-in monitoring via GCS and Eventarc metrics

This Eventarc integration leverages our existing Index structure to create a reliable, automatic event-driven architecture that eliminates the complexity and failure modes of manual event publishing.